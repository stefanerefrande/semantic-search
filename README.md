# üöÄ PoC: Semantic Search with Embeddings and Elasticsearch

## Project Overview

This project is a **Proof of Concept (PoC)** demonstrating the implementation of **Semantic Search** within a product API, utilizing **Vector Embeddings** generated by a **GenAI Platform** and **Elasticsearch** as the search engine. In addition to purely semantic search (KNN), the project also compares results with a **traditional Lexical Search** and a **Hybrid Search** (combining lexical and semantic), offering a comprehensive view of different approaches.

The main goal is to explore how embeddings can be used to enhance the relevance of search results, especially for natural language queries or terms that do not exactly match literal keywords in documents.

## ‚ú® Implemented Features

* **Data Collection**: Extracts products from an existing Elasticsearch index (simulating a product catalog).
* **Embedding Generation**: Sends product descriptions to an external GenAI API (simulated) to obtain vector representations (embeddings).
* **Elasticsearch Indexing**: Indexes the enriched products with their respective embeddings in Elasticsearch.
* **Semantic Search (KNN)**: Performs searches using only the vector similarity (K-Nearest Neighbors) of embeddings.
* **Lexical Search (Multi-Match)**: Executes traditional keyword-based searches using `multi_match` with field weighting.
* **Hybrid Search (Combined)**: Conducts searches that combine the power of lexical and semantic search for more relevant results.
* **Flexible Configuration**: All sensitive configurations (API URLs, keys, etc.) are managed via environment variables (`.env`), facilitating setup in different environments and ensuring credential security.
* **Detailed Logging**: Uses Python's `logging` module to provide clear feedback on execution status, errors, and warnings.
* **Results Export**: Saves the results of each search type (semantic, hybrid, lexical) into separate CSV files for analysis and comparison.

## üéØ Why This Project?

In an increasingly data-driven and personalized world, traditional keyword-based search often proves to be limited. This project demonstrates how **Generative Artificial Intelligence** and **Elasticsearch** can be combined to create smarter search systems capable of understanding the intent behind user queries, even if the exact terms are not present in the document text.

It's a practical proof of how advanced NLP and vector search concepts can be applied to solve real business problems and enhance the user experience.

## üõ†Ô∏è Technologies Used

* **Python 3.8+**
* **Elasticsearch**
* **Elasticsearch-py** (Python Client for Elasticsearch)
* **Requests** (For HTTP calls to external APIs)
* **Pandas** (For data manipulation and CSV export)
* **python-dotenv** (For environment variable management)
* **GenAI Platform (Embeddings API)**: Represents an external API for embedding generation (e.g., OpenAI, Google AI, Azure AI Services, etc. - the URL in the code is a placeholder).

## üöÄ How to Run the Project

Follow the steps below to set up and run the PoC in your local environment.

### Prerequisites

* Python 3.8+ installed.
* Access to an Elasticsearch instance (local or remote).
* Access to an Embedding Generation API (the code uses a placeholder URL; you'll need a real API and its respective key, if applicable).

### Setup Steps

1.  **Clone the Repository:**
    ```bash
    git clone [https://github.com/stefanerefrande/semantic-search.git](https://github.com/stefanerefrande/semantic-search.git)
    cd semantic-search
    ```

2.  **Create and Activate a Virtual Environment:**
    ```bash
    python -m venv venv
    # On Windows
    .\venv\Scripts\activate
    # On Linux/macOS
    source venv/bin/activate
    ```

3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```

4.  **Configure Environment Variables:**
    Create a `.env` file in the project root (`semantic-search-poc/`) based on `.env.example`.
    **Important**: Fill in the variables with your actual values, especially Elasticsearch URLs and GenAI API keys.


5.  **Prepare the Search Terms File:**
    Check the `terms_to_search.txt` file in the project root. It should contain one search term per line. Edit it as needed.

    Example:
    ```
    floral perfume
    natural makeup
    anti-dandruff shampoo
    face cream for dry skin
    mother's day gift set
    ```

6.  **Execute the Project:**
    ```bash
    python src/main.py
    ```

## üìà Results

Upon completion, the search results (Semantic, Hybrid, and Lexical) for each term will be saved in CSV files within the `results/` directory. A `results/summary_vector_search_tests.csv` file will also be generated, providing a consolidated summary of all tests, including execution times.